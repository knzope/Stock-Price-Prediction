{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#importing required libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADANIPORTS', 'ASIANPAINT', 'AXISBANK', 'BAJAJ-AUTO', 'BAJAJFINSV',\n",
       "       'BAJFINANCE', 'BHARTIARTL', 'BPCL', 'BRITANNIA', 'CIPLA',\n",
       "       'COALINDIA', 'DRREDDY', 'EICHERMOT', 'GAIL', 'GRASIM', 'HCLTECH',\n",
       "       'HDFC', 'HDFCBANK', 'HEROMOTOCO', 'HINDALCO', 'HINDUNILVR',\n",
       "       'ICICIBANK', 'INDUSINDBK', 'INFRATEL', 'INFY', 'IOC', 'ITC',\n",
       "       'JSWSTEEL', 'KOTAKBANK', 'LT', 'MARUTI', 'MM', 'NESTLEIND',\n",
       "       'NIFTY50_all', 'NTPC', 'ONGC', 'POWERGRID', 'RELIANCE', 'SBIN',\n",
       "       'SHREECEM', 'stock_metadata', 'SUNPHARMA', 'TATAMOTORS',\n",
       "       'TATASTEEL', 'TCS', 'TECHM', 'TITAN', 'ULTRACEMCO', 'UPL', 'VEDL',\n",
       "       'WIPRO', 'ZEEL'], dtype='<U14')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names=['ADANIPORTS', 'ASIANPAINT', 'AXISBANK', 'BAJAJ-AUTO', 'BAJAJFINSV',\n",
    "       'BAJFINANCE', 'BHARTIARTL', 'BPCL', 'BRITANNIA', 'CIPLA',\n",
    "       'COALINDIA', 'DRREDDY', 'EICHERMOT', 'GAIL', 'GRASIM', 'HCLTECH',\n",
    "       'HDFC', 'HDFCBANK', 'HEROMOTOCO', 'HINDALCO', 'HINDUNILVR',\n",
    "       'ICICIBANK', 'INDUSINDBK','INFY', 'IOC', 'ITC',\n",
    "       'JSWSTEEL', 'KOTAKBANK', 'LT', 'MARUTI', 'MM', 'NESTLEIND', \n",
    "       'NTPC', 'ONGC', 'POWERGRID', 'RELIANCE', 'SBIN',\n",
    "       'SHREECEM', 'SUNPHARMA', 'TATAMOTORS',\n",
    "       'TATASTEEL', 'TCS', 'TECHM', 'TITAN', 'ULTRACEMCO', 'UPL', 'VEDL',\n",
    "       'WIPRO', 'ZEEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3905/3905 - 56s - loss: 0.0013\n",
      "3905/3905 - 55s - loss: 0.0011\n",
      "3905/3905 - 55s - loss: 0.0011\n",
      "3905/3905 - 55s - loss: 0.0014\n",
      "3556/3556 - 52s - loss: 0.0017\n",
      "3905/3905 - 58s - loss: 0.0016\n",
      "3905/3905 - 58s - loss: 5.4070e-04\n",
      "3905/3905 - 56s - loss: 0.0018\n",
      "3905/3905 - 56s - loss: 0.0019\n",
      "3905/3905 - 57s - loss: 3.3548e-04\n",
      "3905/3905 - 58s - loss: 2.7751e-04\n"
     ]
    }
   ],
   "source": [
    "for ind in range(len(file_names)):\n",
    "    df = pd.read_csv('datasets/'+file_names[ind]+'.csv')\n",
    "    #creating dataframe\n",
    "    data = df.sort_index(ascending=True, axis=0)\n",
    "    new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
    "    for i in range(0,len(data)):\n",
    "        new_data['Date'][i] = data['Date'][i]\n",
    "        new_data['Close'][i] = data['Close'][i]\n",
    "\n",
    "    #setting index\n",
    "    new_data.index = new_data.Date\n",
    "    new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "    #creating train and test sets\n",
    "    dataset = new_data.values\n",
    "\n",
    "    train = dataset[0:3965,:]\n",
    "    valid = dataset[3965:,:]\n",
    "\n",
    "    dataset\n",
    "\n",
    "    #converting dataset into x_train and y_train\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "    x_train, y_train = [], []\n",
    "    for i in range(60,len(train)):\n",
    "        x_train.append(scaled_data[i-60:i,0])\n",
    "        y_train.append(scaled_data[i,0])\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "\n",
    "    # create and fit the LSTM network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2)\n",
    "    model.save_weights(\"SavedModels/\"+file_names[ind]+\".h5\")\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
